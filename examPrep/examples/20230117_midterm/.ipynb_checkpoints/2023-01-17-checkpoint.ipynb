{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "bd09799d819bb3301d53cfc25ec1a05a",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# 2023-01-17 Exam\n",
    "\n",
    "### General Instructions:\n",
    "\n",
    "Welcome to the **Python Programming (for Data Science)** exam session! Please, read **carefully** the instructions below before start writing code. \n",
    "This session will last **75 minutes** (plus any additional time gained during the first part of the exam) and is worth 33 points.\n",
    "\n",
    "You will earn all of the points associated to an exercise **if and only if** the answer you provide passes successfully **all** the tests for that exercise (both those that are visible and those that are hidden to you). Some exercises do not have a set of predefined tests and will be evaulated line by line.<br />\n",
    "\n",
    "To actually write down your implementation, make sure to fill in any place that says <code style=\"color:green\">**_# YOUR CODE HERE_**</code>. Note also that you should **either comment or delete** any <code style=\"color:green\">**raise NotImplementedError()**</code> exception.<br />\n",
    "\n",
    "For this exam session **you will not be allowed** to use any lecture material yet you will be able to access the following APIs:\n",
    "\n",
    "-  [Python](https://docs.python.org/)\n",
    "-  [Numpy](https://numpy.org/)\n",
    "-  [Scipy](https://docs.scipy.org/)\n",
    "-  [Pandas](https://pandas.pydata.org/)\n",
    "-  [Matplotlib](https://matplotlib.org/)\n",
    "-  [Seaborn](http://seaborn.pydata.org/)\n",
    "-  [SciKit-Learn](http://scikit-learn.org/stable/)\n",
    "\n",
    "Once you are done, save this notebook and rename it as follows:\n",
    "\n",
    "<code>**YOURUSERNAME_2023-01-17.ipynb**</code>\n",
    "\n",
    "where <code>**YOURUSERNAME**</code> is your actual username. To be consistent, we are expecting your username to be composed by your first name's initial, followed by your full lastname.<br />\n",
    "\n",
    "Finally, go back to [Moodle](https://esami.elearning.unipd.it/), you will be able to upload your notebook file for grading.\n",
    "\n",
    "Note that there is no limit on the number of submissions; however, be careful when you upload a new version of this notebook because each submission overwrites the previous one. \n",
    "The due date indicated above is **strict**; after that, the system will not accept any more submissions and the latest uploaded notebook will be the one considered for grading.\n",
    "\n",
    "The archive you have downloaded (<code style=\"color:magenta\">**20230117_midterm.zip**</code>) is organized as follows:\n",
    "\n",
    "<code style=\"color:red\">**20230117_midterm**</code> (root)<br />\n",
    "|----<code style=\"color:green\">**20230117_exam.ipynb**</code> (_this_ notebook)<br />\n",
    "|----<code>**dataset.csv**</code> (the dataset you will be using for answering data science related questions)<br />\n",
    "|----<code>**factbook.db**</code> (the sqlite database of the CIA factbook)<br />\n",
    "|----<code>**factbook.sql**</code> (the sql code that was used to create the table contained in the factbook.db)<br />\n",
    "|----<code>**README.txt**</code> (a description of the dataset.csv file)\n",
    "\n",
    "<center><h3>... Now, sit back, relax, and do your best!</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "df28b1c7ab22dda58c560c68231fe2dd",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Adding the following line, allows Jupyter Notebook to visualize plots\n",
    "# produced by matplotlib directly below the code cell which generated those.\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from nose.tools import assert_equal\n",
    "from operator import itemgetter\n",
    "\n",
    "EPSILON = .0000001 # tiny tolerance for managing subtle differences resulting from floating point operations\n",
    "\n",
    "DATASET_FILE = \"dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "a52bd02aadcf37b2a9a7902a274b37de",
     "grade": false,
     "grade_id": "part-2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 1 (2 point)\n",
    "\n",
    "In this part, you will be working with the dataset file <code>**dataset.csv**</code>. For a complete description of this data source, please refer to the <code>**README.txt**</code>.\n",
    "In a nutshell, this is a sample of **1,000 instances** from a larger dataset containing census and demographic information for a set of citizens.\n",
    "Each citizen (i.e., row in the file) is described by **14** features (i.e., columns) and labeled with an binary value (i.e., the 15th and last column called <code>**income_greater_than_50k**</code>), which takes on two values: **-1** (indicating the citizen's yearly income is **below or equal than** 50k dollars) or **+1**, otherwise.<br />\n",
    "The cell below is responsible for correctly loading the dataset from the <code>**dataset.csv**</code> file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "fc9f53954bf9a264ce3644816b3d9476",
     "grade": false,
     "grade_id": "part-2-required",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset stored at `DATASET_FILE` in a variable named \"data\", \n",
    "# use \",\" as field separator and '?' to detect NAs\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# check the first lines of your dataset\n",
    "data.head()\n",
    "\n",
    "## THERE IS NO TEST OF CORRECTNESS FOR THIS PART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "f2f21c70d077c99447baa15fd4d24d31",
     "grade": false,
     "grade_id": "exercise-2-1-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2 (3 point)\n",
    "\n",
    "Implement the function <code>**avg_capital_gain_per_age**</code> below. This takes as input a <code>**pandas.DataFrame**</code> object and an integer value <code>**age**</code>, and returns the **average** value of <code>**capital_gain**</code> of citizens having that age.\n",
    "\n",
    "(**NOTE:** If the information abuot age is missing in a record, the <code>**mean()**</code> function is robust and returns <code>**np.nan**</code>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "b68b3232f9f44f7019a50215ccb0f621",
     "grade": false,
     "grade_id": "exercise-2-1-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def avg_capital_gain_per_age(dataframe, age):\n",
    "    \"\"\"\n",
    "    Return the average value of capital gain for citizens having a specific age.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "adcd920200e5b732a2a653cfed878063",
     "grade": true,
     "grade_id": "exercise-2-1-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of the implementation of the `avg_capital_gain_per_age` function\n",
    "\"\"\"\n",
    "\n",
    "assert_equal(True, np.abs(192.80769230769232 - avg_capital_gain_per_age(data, 32)) < EPSILON)\n",
    "assert_equal(0.0, avg_capital_gain_per_age(data, 27))\n",
    "assert_equal(2330.0, avg_capital_gain_per_age(data, 48))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "ee3b7bfac50d3363762e53cf35b5ba4b",
     "grade": false,
     "grade_id": "exercise-2-2-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 3 (4 point)\n",
    "\n",
    "Implement the function <code>**hours_per_week_stats**</code> below. This takes as input a <code>**pandas.DataFrame**</code> object and returns a tuple containing the min, max, avg, and median value of <code>**hours_per_week**</code>, yet computed on a _slice_ of the input <code>**pandas.DataFrame**</code>.<br />\n",
    "The sliced dataset represents the subpopulation containing **female** citizens whose age is **between 36 and 49 years old** (extremes included), who were born in the **United-States** and having a value of <code>**education_num**</code> **strictly greater than** the _overall_ average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "9e714bddf557ed341cc8ec008361126f",
     "grade": false,
     "grade_id": "exercise-2-2-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def hours_per_week_stats(dataframe):\n",
    "    \"\"\"\n",
    "    Return a tuple containing the min, max, avg, and median value of `hours_per_week` feature,\n",
    "    yet limited to a slice of the input DataFrame (data). \n",
    "    In particular, this slice will contain instances referring to female citizens\n",
    "    whose age is between 36 and 49 (extremes included) born in the United-States\n",
    "    and having a value of education_num strictly above the overall population average.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "3950b368373b4fe2f374e1cc94f98255",
     "grade": true,
     "grade_id": "exercise-2-2-test",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of the implementation of the `hours_per_week_stats` function\n",
    "\"\"\"\n",
    "\n",
    "# Call off `hours_per_week_stats` function\n",
    "stats = hours_per_week_stats(data)\n",
    "\n",
    "assert_equal(5, stats[0])\n",
    "assert_equal(60, stats[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "167926701c33e36728bb7b47f90ec032",
     "grade": false,
     "grade_id": "exercise-2-3-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 4 (4 points)\n",
    "\n",
    "Implement the function <code>**standardize_dataset**</code>, which takes as input a <code>**pandas.DataFrame**</code> object and modifies it by creating **new** columns corresponding to the **standardized** values of _numerical_ columns only, except for the target column, i.e., the very last column named <code>**income_greater_than_50k**</code>.<br />\n",
    "To standardize a column $X$, each original value $x\\in X$ should be modified with $x_{\\text{std}}$ as follows:\n",
    "\n",
    "$$\n",
    "x_{\\text{std}} = \\frac{x - \\mu_X}{\\sigma_X}\n",
    "$$\n",
    "\n",
    "where $\\mu_X$ and $\\sigma_X$ are the **mean** and **standard deviation** computed across $X$, respectively.\n",
    "\n",
    "To be sure standardization is applied to a numerical column only, you can use the following built-in function:\n",
    "\n",
    "<code>**pd.api.types.infer_dtype(data[column], skipna=True)**</code>.\n",
    "\n",
    "If the value returned by this function is equal to the string <code>**'integer'**</code>, then you can apply the standardization.\n",
    "\n",
    "Finally, the naming convention for standardized columns is as follows: if <code>**column**</code> is the name of the original column, then its standardized version will be <code>**column_std**</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "0f275f76c9ea80f47070fb325f1bdb4d",
     "grade": false,
     "grade_id": "exercise-2-3-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def standardize_dataset(dataframe):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "8dd2f08b5ce5abdef5e30eb10e0cf870",
     "grade": true,
     "grade_id": "exercise-2-3-test",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of the implementation of the `standardize_dataset` function\n",
    "\"\"\"\n",
    "\n",
    "# Call off `standardize_dataset` function on a copy of our original dataset\n",
    "data_cpy = data.copy()\n",
    "standardize_dataset(data_cpy)\n",
    "\n",
    "assert_equal(1000, data_cpy.shape[0])\n",
    "assert_equal(21, data_cpy.shape[1])\n",
    "assert_equal(True, np.abs(0.093258105603949315 - data_cpy.iloc[42]['age_std']) < EPSILON)\n",
    "assert_equal(True, np.abs(-0.21956059890921917 - data_cpy.iloc[73]['capital_loss_std']) < EPSILON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "d2b3af702cfead9c97f78c8887f2ce01",
     "grade": false,
     "grade_id": "exercise-2-4-1-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 5 (4 point)\n",
    "\n",
    "Connect to the CIA Factbook database factbook.db and use an SQL query to select all the data contained in the table *facts*. Build a pandas DataFrame with the result set in a varibale named *countries*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "92e86bad0a1645fafef2d4d58cd7d014",
     "grade": false,
     "grade_id": "exercise-2-4-1-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "## THERE IS NO TEST OF CORRECTNESS FOR THIS PART\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6 (4 point)\n",
    "\n",
    "Merge the dataframe *data* created in exercise 1 and the dataframe *countries* built in the previous exercise using the columns *native_country* and *name*, respectvely. Save the result in a new dataframe names *data_ext*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the correctness of `dist_plot_age`, `mu` and `sigma`\n",
    "\"\"\"\n",
    "\n",
    "assert_equal(True, (data_ext.shape[0] == 56))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7 (3 point)\n",
    "\n",
    "Split the *data_ext* dataframe into two dataframes using the \"masking\" approach. One dataframe, named \"lower\", must contain the rows of *data_ext* that have a population lower than the mean of the population of the dataframe *countries*; the other dataframe, named \"gr_eq\", must contain the rows of *data_ext* that have a population greater or equal than the mean of the population of the dataframe *countries*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "## THERE IS NO TEST OF CORRECTNESS FOR THIS PART\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "c038056da5a06fe1fabac57e8f86e607",
     "grade": false,
     "grade_id": "exercise-2-4-2-text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise 8 (3 points)\n",
    "\n",
    "Build a Figure object and create a 1 x 2 matrix of subplots.\n",
    "In the first subplot you must plot the distribution of the numerical feature <code>**age**</code> of the subset of data of countries with a popoulation lower than the mean using the <code>**distplot**</code> function.\n",
    "In the second subplot you must plot the distribution of the numerical feature <code>**age**</code> of the subset of data of countries with a popoulation greater or equal than the mean using the <code>**boxplot**</code> function.\n",
    "Replace \"?\" with the appropriate code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's produce the boxplots corresponding to the required distribution plots \n",
    "# Create a Figure containing 2x2 subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,12))\n",
    "\n",
    "# YOUR CODE HERE (substitute \"?\" with the appropriate variable)\n",
    "sns.boxplot(x = ?, color='#808080', ax=axes[0])\n",
    "sns.boxplot(x = ?, color='#df2020', ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning (6 points)\n",
    "\n",
    "In this part, you will be able to show your machine learning skills! Use the scikit-learn package to import all the subpackages that you need. Please follow the structure indicated in the following steps to train a classifier of your choice. \n",
    "\n",
    "**The goal is to predict whether the income of a person is greater than 50k!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import the packages you need\n",
    "\"\"\"\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Extract the feature matrix X from our original DataFrame (you can choose the columns).\n",
    "\"\"\"\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Similarly, we want to extract the target class column vector y.\n",
    "\"\"\"\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Use a simple stratified train/test split\n",
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = # YOUR CODE HERE\n",
    "\n",
    "\n",
    "print(\"Training Set shape: {}\".format(X_train.shape))\n",
    "print(\"Test Set shape: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Implement the following code to train a model of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Fit the model to the training set\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Run the following code to implement a function which evaluates the effectiveness of your classifier.\n",
    "This function has already been implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "General function used to assess the quality of predictions\n",
    "in terms of two scores: accuracy and ROC AUC (Area Under the ROC Curve)\n",
    "\"\"\"\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate(true_values, predicted_values):\n",
    "    # Classification Accuracy\n",
    "    print(\"Accuracy = {:.3f}\".\n",
    "          format(accuracy_score(true_values, predicted_values)))\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print(\"Area Under the ROC Curve (ROC AUC) = {:.3f}\".\n",
    "          format(roc_auc_score(true_values, predicted_values)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the following code to test your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the quality of predictions made on the test set\n",
    "print(\"***** Evaluate Performance on Test Set *****\") \n",
    "\n",
    "### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
